Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
12000,1.4189383,21.742424242424242,0.038514752,1.1726754924151657,1.1726754924151657,1.0
24000,1.4198859,22.940119760479043,-0.03556117,1.2972055523695347,1.2972055523695347,1.0
36000,1.4134023,24.81935483870968,0.059165247,1.478064469111863,1.478064469111863,1.0
48000,1.3942115,32.844632768361585,0.22032492,2.2861971237290075,2.2861971237290075,1.0
60000,1.3817676,41.81428571428572,0.46613213,3.178214363540922,3.178214363540922,1.0
72000,1.3677381,73.38125,0.761538,6.334162384826945,6.334162384826945,1.0
84000,1.351392,104.85087719298245,1.0592089,9.424562895507144,9.424562895507144,1.0
96000,1.3372699,304.05,1.6027946,28.89000430703163,28.89000430703163,1.0
108000,1.3310148,605.2,2.060683,57.71500892043114,57.71500892043114,1.0
120000,1.3199215,791.6666666666666,2.5282776,82.18001263936361,82.18001263936361,1.0
132000,1.3139354,773.875,2.8813334,72.7750108987093,72.7750108987093,1.0
144000,1.3056924,942.1666666666666,3.5184348,100.00001525878906,100.00001525878906,1.0
156000,1.2988944,972.3076923076923,3.983375,91.91539881779597,91.91539881779597,1.0
168000,1.2948093,999.0,4.405064,100.00001525878906,100.00001525878906,1.0
180000,1.2911363,999.0,4.8618264,100.00001525878906,100.00001525878906,1.0
192000,1.287158,999.0,5.330102,100.00001525878906,100.00001525878906,1.0
204000,1.284505,999.0,5.7508187,100.00001525878906,100.00001525878906,1.0
216000,1.2815276,999.0,6.0933976,100.00001525878906,100.00001525878906,1.0
228000,1.2777239,883.3076923076923,6.3344946,92.4769371656271,92.4769371656271,1.0
240000,1.2758254,999.0,6.7087283,95.43334833780925,95.43334833780925,1.0
252000,1.2749192,950.6923076923077,6.991497,100.00001525878906,100.00001525878906,1.0
